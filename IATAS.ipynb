{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNgGZbZqVNJAsPDJ2M221+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Topher254/ASA/blob/main/IATAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "tUWug0eUS02W",
        "outputId": "ff780d95-8468-4d13-9534-a33c3436876b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-09a1a07d346d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcvzone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import cvzone\n",
        "import math\n",
        "import numpy as np\n",
        "from sort import *\n",
        "import requests #for http requests\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "API_URL = \"http://localhost:5002/api/ads\"\n",
        "\n",
        "def ai_model():\n",
        "    start_time = time.time()\n",
        "    counter = 0\n",
        "\n",
        "    while True:\n",
        "        model = YOLO('../YoloWeights/yolov8n.pt')\n",
        "\n",
        "        classNames=['Person']\n",
        "        # using images\n",
        "        # results = model('./Assets/1.jpeg',show=True)\n",
        "        # using webcam\n",
        "        # using opencv then we put the bounding boxes\n",
        "        # camera object\n",
        "        # cap=cv2.VideoCapture(0)\n",
        "        # # above is camera no then below the width and height\n",
        "        # cap.set(3,720)\n",
        "        # cap.set(4,720)\n",
        "        # using saved videos\n",
        "        cap=cv2.VideoCapture(\"../Assets/video2.mp4\")\n",
        "        mask = cv2.imread(\"../Assets/mask.png\")\n",
        "\n",
        "        # sorting instance\n",
        "        tracker = Sort(max_age=20,min_hits=2,iou_threshold=0.3)\n",
        "\n",
        "        # we draw a line across,so that if a person goes past it we count them: but later it is once we detect a persons eyes\n",
        "\n",
        "        line_limits = [80,400,1200,400]\n",
        "        total_count = []\n",
        "        daily_views =0\n",
        "        weekly_views=[]\n",
        "        monthly_views=[]\n",
        "        test_location= \"Nairobi\"\n",
        "\n",
        "        while True:\n",
        "            success, img = cap.read()\n",
        "            # overlay the mask on the image: we imagine the mask is the camera lens width\n",
        "            # print(\"Image shape\",img.shape) #shape has issues,we had to check for width and height before masking on top\n",
        "            # print(\"Mask shape\",mask.shape)\n",
        "            mask = cv2.resize(mask,(img.shape[1],img.shape[0]))\n",
        "            image_Region = cv2.bitwise_and(img,mask)\n",
        "\n",
        "            # graphiscs\n",
        "            image_graphics =cv2.imread(\"../Assets/2.jpg\",cv2.IMREAD_UNCHANGED)\n",
        "            if image_graphics.shape[2] == 3:  # If it only has 3 channels (RGB)\n",
        "                image_graphics = cv2.cvtColor(image_graphics, cv2.COLOR_BGR2BGRA)  # Convert to 4 channels\n",
        "                # Resize by a scale factor (e.g., 50% of the original size)\n",
        "                scale_percent = 50\n",
        "                width = int(image_graphics.shape[1] * scale_percent / 100)\n",
        "                height = int(image_graphics.shape[0] * scale_percent / 100)\n",
        "                new_size = (width, height)\n",
        "\n",
        "                # Resize image\n",
        "                image_graphics = cv2.resize(image_graphics, new_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                cvzone.overlayPNG(img,image_graphics,(0,0))\n",
        "\n",
        "            results = model(image_Region,stream=True)\n",
        "            # check for individual bounding boxes\n",
        "            detections = np.empty((0,5))\n",
        "\n",
        "            cv2.line(img, (line_limits[0], line_limits[1]), (line_limits[2], line_limits[3]), (0, 0, 255), 2)\n",
        "\n",
        "            for r in results:\n",
        "                boxes = r.boxes\n",
        "                for box in boxes:\n",
        "                    x1,y1,x2,y2 = box.xyxy[0]\n",
        "                    # convert the tensor to integeres\n",
        "                    x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
        "                    # print(x1,y1,x2,y2)\n",
        "                    # create rectangle\n",
        "                    # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
        "                    # fancy rectangle from cvzone\n",
        "                    w,h=x2-x1,y2-y1\n",
        "\n",
        "                    # confidence values\n",
        "                    conf=math.ceil((box.conf[0]*200))/100\n",
        "\n",
        "                    # then we get the class based on a dataset\n",
        "                    # classname\n",
        "                    class_id = int(box.cls[0])\n",
        "                    if class_id==0 and conf>0.3:\n",
        "                        # cvzone.cornerRect(img,(x1,y1,w,h),l=15)\n",
        "                        # cvzone.putTextRect(img,f'{classNames[class_id]}{conf}',(max(0,x1),max(30,y1)),scale=0.8,thickness=2)\n",
        "                        # once detected,we add it to our detection array\n",
        "                        current_array = np.array([x1,y1,x2,y2,conf])\n",
        "                        # do vertical stack\n",
        "                        # print(\"detections shape:\", detections.shape)\n",
        "                        # print(\"current_array shape:\", current_array.shape)\n",
        "                        # current_array = current_array.reshape(1, 5)\n",
        "                        detections = np.vstack((detections,current_array))\n",
        "\n",
        "                # to count the people we have to draw a line\n",
        "                # then one a person goes past the line we count them\n",
        "                # each person should be assigned an Id to keep track iof them\n",
        "                # within the frames we must know where our person is moving to\n",
        "                # we will use a tracker,such as sort by abewley\n",
        "                # https://github.com/abewley/sort\n",
        "\n",
        "\n",
        "            tracker_results = tracker.update(detections)\n",
        "            for result in tracker_results:\n",
        "                x1,y2,x2,y2,Id = result\n",
        "                x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
        "                print(result)\n",
        "                cvzone.cornerRect(img,(x1,y1,w,h),l=9,rt=1,t=2,colorC=(255,0,0),colorR=(0,255,0))\n",
        "                cvzone.putTextRect(img,f'{int(Id)}',(max(0,x1),max(30,y1)),scale=2,thickness=2)\n",
        "                # let's get the center point.. if it touches the line we count the person\n",
        "                centerx,centery= int(x1+w/2),int(y1+h/2)\n",
        "                cv2.circle(img,(centerx,centery),5,(255,0,255),cv2.FILLED)\n",
        "\n",
        "                if line_limits[0] <centerx<line_limits[2] and line_limits[1]-50<centery<line_limits[1]+50:\n",
        "                    if total_count.count(Id)==0:\n",
        "                        total_count.append(Id)\n",
        "                            #  debuggin count\n",
        "                        #  print(\"total count is:\",total_count)\n",
        "\n",
        "\n",
        "                        cv2.line(img, (line_limits[0], line_limits[1]), (line_limits[2], line_limits[3]), (0, 255, 0), 2)\n",
        "\n",
        "                    # check if id is alerady counted\n",
        "\n",
        "            cvzone.putTextRect(img,f'Count:{int(len(total_count))}',(0,50),scale=2,thickness=2,colorR=(0,255,2),colorT=(255, 0, 255))\n",
        "\n",
        "            count_in_total = int(len(total_count))\n",
        "            print(f\"Current Count\",count_in_total)\n",
        "\n",
        "            if time.time()-start_time >=60:\n",
        "                try:\n",
        "                    response = requests.post(API_URL,json={\"views\":count_in_total,\"location\":test_location})\n",
        "                    print(response.status_code, response.text)\n",
        "                    print(f\"Sent {count_in_total} views to backend: {response.json()}\")\n",
        "                    start_time=time.time()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(\"Error Sending data:...\",e)\n",
        "            time.sleep(1)\n",
        "\n",
        "            cv2.imshow(\"Image\",img)\n",
        "            # cv2.imshow(\"ImageRegion\",image_Region)\n",
        "            cv2.waitKey(1)\n",
        "\n",
        "\n",
        "\n",
        "ai_model()\n"
      ]
    }
  ]
}